# CartPole Episode Reward Prediction using Machine Learning

## Overview

This project uses OpenAI Gymnasium's CartPole-v1 environment to generate simulation data and predicts episode rewards using various machine learning regression models. The goal is to determine which regression algorithm best predicts the total reward an episode will achieve based on the final state variables of the CartPole system.

## Methodology

### 1. Environment Setup

The project uses the **CartPole-v1** environment from OpenAI Gymnasium. CartPole is a classic reinforcement learning problem where a pole is attached to a cart moving along a frictionless track. The system has four state variables:

- **Cart Position**: Horizontal position of the cart
- **Cart Velocity**: Speed of the cart's movement
- **Pole Angle**: Angle of the pole from vertical
- **Pole Angular Velocity**: Rate of change of the pole's angle

### 2. Data Generation

Data was generated by running **1,000 episodes** of the CartPole environment with random actions:

```
Episodes: 1000
Action Strategy: Random sampling from action space
State Variables: 4 (cart_position, cart_velocity, pole_angle, pole_angular_velocity)
Target Variable: episode_reward (total steps before termination)
```

Each episode:
1. Starts with a reset environment
2. Takes random actions until termination (pole falls or cart moves out of bounds)
3. Records the final state variables and total episode reward
4. The episode reward represents how long the pole stayed balanced

**Sample Data:**

| cart_position | cart_velocity | pole_angle | pole_angular_velocity | episode_reward |
|---------------|---------------|------------|----------------------|----------------|
| 0.062090      | 0.951053      | -0.230231  | -1.783494            | 11.0           |
| -0.153119     | -0.632762     | 0.218400   | 1.118507             | 13.0           |
| 0.145367      | 1.189654      | -0.244695  | -2.130400            | 18.0           |
| 0.170634      | 0.358668      | -0.229332  | -0.857255            | 12.0           |
| 0.190781      | 1.403324      | -0.230899  | -2.408421            | 25.0           |

### 3. Data Preprocessing

**Train-Test Split:**
- Training Set: 80% (800 samples)
- Test Set: 20% (200 samples)
- Random State: 42 (for reproducibility)

**Feature Scaling:**
- Applied StandardScaler to normalize all features
- Transforms features to have mean=0 and variance=1
- Prevents features with larger magnitudes from dominating the model

### 4. Machine Learning Models

Six regression models were trained and evaluated:

1. **Linear Regression**: Basic linear model assuming linear relationship between features and target
2. **Ridge Regression**: Linear regression with L2 regularization to prevent overfitting
3. **K-Nearest Neighbors (KNN)**: Non-parametric model that predicts based on k nearest training samples
4. **Decision Tree**: Tree-based model that creates binary splits to partition the feature space
5. **Random Forest**: Ensemble of decision trees with bootstrap aggregating
6. **Gradient Boosting**: Sequential ensemble that builds trees to correct previous errors

### 5. Evaluation Metrics

Models were evaluated using three metrics:

- **MAE (Mean Absolute Error)**: Average absolute difference between predictions and actual values
- **RMSE (Root Mean Squared Error)**: Square root of average squared differences (penalizes large errors)
- **R² Score**: Proportion of variance explained by the model (1.0 = perfect, 0.0 = baseline)

## Results

### Model Performance Comparison

The table below shows the performance of all six models, sorted by RMSE (lower is better):

| Model              | MAE      | RMSE     | R² Score |
|--------------------|----------|----------|----------|
| KNN                | 6.633    | 9.076    | 0.417    |
| Random Forest      | 6.982    | 9.166    | 0.405    |
| Gradient Boosting  | 7.475    | 9.773    | 0.324    |
| Decision Tree      | 8.735    | 11.349   | 0.088    |
| Linear Regression  | 9.232    | 11.690   | 0.033    |
| Ridge Regression   | 9.243    | 11.708   | 0.030    |

### Key Findings

1. **Best Model: K-Nearest Neighbors (KNN)**
   - Achieved the lowest RMSE of 9.076
   - Highest R² score of 0.417, explaining 41.7% of variance
   - MAE of 6.633 indicates predictions are off by ~6-7 steps on average

2. **Second Best: Random Forest**
   - Very close performance to KNN (RMSE: 9.166)
   - R² score of 0.405
   - More robust and less prone to overfitting than single trees

3. **Poor Performance: Linear Models**
   - Linear and Ridge regression performed worst
   - R² scores near 0.03 indicate poor fit
   - Suggests non-linear relationship between state variables and rewards

4. **Ensemble Methods Outperform**
   - Random Forest and Gradient Boosting (ensemble methods) outperformed Decision Tree
   - Demonstrates the power of combining multiple models

### Visualization: Random Forest Predictions

![Actual vs Predicted Episode Reward](download.png)

**Graph Analysis:**

The scatter plot shows the relationship between actual and predicted episode rewards using the Random Forest model:

- **X-axis**: Actual episode rewards (ground truth)
- **Y-axis**: Predicted episode rewards (model output)
- **Red dashed line**: Perfect prediction line (y = x)
- **Teal points**: Individual test samples

**Observations:**
- Points scattered around the perfect prediction line indicate reasonable performance
- Clustering of points in the 10-30 reward range (most common episode lengths)
- Some spread shows the model struggles with high reward episodes (50+)
- The model tends to underpredict high-performing episodes
- Lower variance in predictions compared to actual values

## Interpretation

The moderate R² scores (max 0.417) suggest that final state variables alone provide limited information about total episode rewards. This makes sense because:

1. **Random Actions**: Episodes used random actions, creating high variability
2. **Final State Focus**: Only final states were recorded, losing trajectory information
3. **Stochastic Nature**: Same final state can result from different episode lengths
4. **Missing Information**: Action history and intermediate states matter significantly

Despite these limitations, KNN and Random Forest captured meaningful patterns, demonstrating that final state variables do contain predictive information about episode performance.

## Dependencies

```
gymnasium[classic_control]
numpy
pandas
matplotlib
scikit-learn
```

Install with:
```bash
pip install gymnasium[classic_control] numpy pandas matplotlib scikit-learn
```

## Usage

Run the simulation:
```bash
python cartpole_regression.py
```

The script will:
1. Generate 1000 episodes of CartPole data
2. Train 6 regression models
3. Display model comparison table
4. Show visualization of Random Forest predictions

## Conclusion

This analysis demonstrates that machine learning regression models can predict CartPole episode rewards with moderate accuracy based on final state variables. KNN emerged as the best performer, suggesting that similar final states tend to produce similar episode lengths. The project highlights the importance of model selection and the value of ensemble methods in handling complex, non-linear relationships in reinforcement learning environments.
